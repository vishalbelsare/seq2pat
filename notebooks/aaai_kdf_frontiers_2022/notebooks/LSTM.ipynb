{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "from ast import literal_eval\n",
    "import gc\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras.backend as K\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scripts.utils import log_msg, precision_reall_f1_report\n",
    "from scripts.models import vanilla_LSTM, CustomStopper, keras_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args={}\n",
    "args['data'] = 'data/sample_data_features.csv'\n",
    "args['feature_space'] = 'data/feature_names.csv'\n",
    "args['test_size'] = 0.2\n",
    "args['seed'] = 123456\n",
    "\n",
    "args['cv_results'] = 'results/cv_vanilla_lstm.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['embedding_dim'] = 10\n",
    "args['num_lstm_units'] = [16, 32, 64, 128]\n",
    "args['input_len'] = 20\n",
    "args['layer_nodes'] = [[512], [256], [128], [64], [32]]\n",
    "\n",
    "args['NFOLDS'] = 3\n",
    "args['num_classes'] = 2\n",
    "args['batch_size'] =1000\n",
    "args['max_epochs'] = 200\n",
    "args['early_stop_start'] = 50\n",
    "args['verbose'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(args['data'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[['sequence']], \n",
    "                                                    data[['label']], \n",
    "                                                    test_size=args['test_size'], \n",
    "                                                    random_state=args['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train['sequence'].apply(lambda x: [int(i) for i in literal_eval(x)]).values\n",
    "X_train = pad_sequences(X_train, maxlen=args['input_len'])\n",
    "\n",
    "X_test = X_test['sequence'].apply(lambda x: [int(i) for i in literal_eval(x)]).values\n",
    "X_test = pad_sequences(X_test, maxlen=args['input_len'])\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=args['NFOLDS'], shuffle=True, random_state=args['seed'])\n",
    "\n",
    "vocab_size = np.max(X_train)+1 \n",
    "\n",
    "results = []\n",
    "log_msg(\">>> Start CV\")\n",
    "for i in range(len(args['num_lstm_units'])):\n",
    "    \n",
    "    for j in range(len(args['layer_nodes'])):\n",
    "        \n",
    "        score = 0\n",
    "        splits = folds.split(X_train, y_train)\n",
    "        \n",
    "        for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "            \n",
    "            X_train_cv, X_valid = X_train[train_index], X_train[valid_index]\n",
    "            y_train_cv, y_valid = y_train[train_index], y_train[valid_index]\n",
    "            \n",
    "            K.clear_session()\n",
    "            gc.collect()\n",
    "    \n",
    "            model = vanilla_LSTM(vocab_size, args['embedding_dim'], \n",
    "                                 args['num_lstm_units'][i], \n",
    "                                 args['input_len'], \n",
    "                                 args['num_classes'], \n",
    "                                 layer_nodes=args['layer_nodes'][j])\n",
    "\n",
    "            early_stop = CustomStopper(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='min', \n",
    "                                       start_epoch=args['early_stop_start'],\n",
    "                                       restore_best_weights=True)\n",
    "\n",
    "            y_train_cv_categorical = keras_categorical(y_train_cv, args['num_classes'])\n",
    "            y_valid_categorical = keras_categorical(y_valid, args['num_classes'])\n",
    "\n",
    "            model.fit(X_train_cv, y_train_cv_categorical, \n",
    "                      batch_size=args['batch_size'], \n",
    "                      epochs=args['max_epochs'], \n",
    "                      validation_data=(X_valid, y_valid_categorical),\n",
    "                      verbose=args['verbose'],\n",
    "                      callbacks=[early_stop])\n",
    "\n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "#             print(f\"\\n>>> Fold {fold_n + 1} | AUC: {roc_auc_score(y_valid, y_pred_valid[:,1])}\\n\")\n",
    "\n",
    "            score += roc_auc_score(y_valid, y_pred_valid[:, 1]) / args['NFOLDS']\n",
    "\n",
    "            del X_train_cv, X_valid, y_train_cv, y_train_cv_categorical, y_valid, y_valid_categorical\n",
    "            del model, y_pred_valid, early_stop\n",
    "        \n",
    "        del splits\n",
    "            \n",
    "        results.append({'num_lstm_units' : args['num_lstm_units'][i],\n",
    "                   'layer_nodes' : args['layer_nodes'][j],\n",
    "                   'score': score})\n",
    "\n",
    "        log_msg(f\">>> num_lstm_units={args['num_lstm_units'][i]} layer_nodes={args['layer_nodes'][j]} Mean AUC = {score}\")\n",
    "\n",
    "log_msg(\">>> Finished!\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(args['cv_results'], index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['final_params'] = {'num_lstm_units': 64,\n",
    "                        'layer_nodes': [512]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final, X_valid, y_train_final, y_valid = train_test_split(X_train, y_train, \n",
    "                                                                  test_size=0.1, random_state=args['seed'])\n",
    "\n",
    "vocab_size = np.max(X_train)+1 \n",
    "\n",
    "model = vanilla_LSTM(vocab_size, args['embedding_dim'], \n",
    "                         args['final_params']['num_lstm_units'], \n",
    "                         args['input_len'], args['num_classes'], \n",
    "                         layer_nodes=args['final_params']['layer_nodes'])\n",
    "    \n",
    "early_stop = CustomStopper(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='min', \n",
    "                           start_epoch=args['early_stop_start'],\n",
    "                           restore_best_weights=True)\n",
    "\n",
    "y_train_final_categorical = keras_categorical(y_train_final, args['num_classes'])\n",
    "y_valid_categorical = keras_categorical(y_valid, args['num_classes'])\n",
    "\n",
    "print(\">>> Training \")\n",
    "model.fit(X_train_final, y_train_final_categorical, \n",
    "          batch_size=args['batch_size'], \n",
    "          epochs=args['max_epochs'], \n",
    "          validation_data=(X_valid, y_valid_categorical),\n",
    "          verbose=args['verbose'],\n",
    "          callbacks=[early_stop])\n",
    "\n",
    "print(\">>> Finished!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_valid)\n",
    "y_pred = y_pred[:,1]\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_valid, y_pred)\n",
    "\n",
    "reports = precision_reall_f1_report(precision, recall, thresholds, \n",
    "                                    font_scale=2,\n",
    "                                    linewidth=3,\n",
    "                                    plot=False)\n",
    "\n",
    "threshold = reports[reports['f1']==reports['f1'].max()]['threshold'].values[0]\n",
    "\n",
    "print('Threshold to get the best F1 on validation set: ', threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred[:,1]\n",
    "\n",
    "print(f\">>> AUC on Test set: {roc_auc_score(y_test, y_pred)}\\n\")\n",
    "\n",
    "y_pred_label = [1 if i >= threshold else 0 for i in y_pred]\n",
    "\n",
    "print(f\">>> F1 on Test set (threshold {threshold}) : {f1_score(y_test, y_pred_label)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, Recall and F1 vs threshold on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = precision_reall_f1_report(precision, recall, thresholds, \n",
    "                                    font_scale=2,\n",
    "                                    linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best F1: ', reports['f1'].max())\n",
    "print('Threshold:', reports[reports['f1']==reports['f1'].max()]['threshold'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
