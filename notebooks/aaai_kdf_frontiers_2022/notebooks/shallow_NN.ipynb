{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "import gc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.models import Model, Sequential\n",
    "from keras import initializers, regularizers, optimizers, layers\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scripts.utils import log_msg, precision_reall_f1_report\n",
    "from scripts.models import shallow_NN, CustomStopper, keras_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args={}\n",
    "args['data'] = 'data/sample_data_features.csv'\n",
    "args['feature_space'] = 'data/feature_names.csv'\n",
    "args['test_size'] = 0.2\n",
    "args['seed'] = 123456\n",
    "\n",
    "args['cv_results'] = 'results/cv_shallow_NN.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['layer_nodes'] = [[512], [256], [128], [64], [32]]\n",
    "\n",
    "args['NFOLDS'] = 3\n",
    "args['num_classes'] = 2\n",
    "args['batch_size'] =1000\n",
    "args['max_epochs'] = 200\n",
    "args['early_stop_start'] = 50\n",
    "args['verbose'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(args['data'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(['sequence', 'label'], axis=1), \n",
    "                                                    data[['label']], \n",
    "                                                    test_size=args['test_size'], \n",
    "                                                    random_state=args['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=args['NFOLDS'], shuffle=True, random_state=args['seed'])\n",
    "\n",
    "columns = X_train.columns\n",
    "\n",
    "\n",
    "results = []\n",
    "log_msg(\">>> Start CV\")\n",
    "for i in range(len(args['layer_nodes'])):\n",
    "\n",
    "    gc.collect()\n",
    "    score = 0\n",
    "    splits = folds.split(X_train, y_train)\n",
    "\n",
    "    for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "\n",
    "        K.clear_session()\n",
    "        gc.collect()\n",
    "\n",
    "        X_train_cv, X_valid = X_train[columns].iloc[train_index].values, X_train[columns].iloc[valid_index].values\n",
    "        y_train_cv, y_valid = y_train.iloc[train_index].values, y_train.iloc[valid_index].values\n",
    "\n",
    "        model = shallow_NN(len(columns), args['num_classes'], layer_nodes=args['layer_nodes'][i])\n",
    "\n",
    "        early_stop = CustomStopper(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='min', \n",
    "                                   start_epoch=args['early_stop_start'],\n",
    "                                   restore_best_weights=True)\n",
    "\n",
    "        y_train_cv_categorical = keras_categorical(y_train_cv, args['num_classes'])\n",
    "        y_valid_categorical = keras_categorical(y_valid, args['num_classes'])\n",
    "\n",
    "        model.fit(X_train_cv, y_train_cv_categorical, \n",
    "                  batch_size=args['batch_size'], \n",
    "                  epochs=args['max_epochs'], \n",
    "                  validation_data=(X_valid, y_valid_categorical),\n",
    "                  verbose=args['verbose'],\n",
    "                  callbacks=[early_stop])\n",
    "\n",
    "        y_pred_valid = model.predict(X_valid)\n",
    "\n",
    "        score += roc_auc_score(y_valid, y_pred_valid[:, 1]) / args['NFOLDS']\n",
    "\n",
    "        del X_train_cv, X_valid, y_train_cv, y_train_cv_categorical, y_valid, y_valid_categorical\n",
    "        del model\n",
    "\n",
    "    results.append({'layer_nodes' : args['layer_nodes'][i],\n",
    "               'score': score})\n",
    "\n",
    "    log_msg(f\">>> layer_nodes={args['layer_nodes'][i]} Mean AUC = {score}\")\n",
    "\n",
    "log_msg(\">>> Finished!\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(args['cv_results'], index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['final_params'] = {'layer_nodes': [512]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final, X_valid, y_train_final, y_valid = train_test_split(X_train, y_train, \n",
    "                                                                  test_size=0.1, random_state=args['seed'])\n",
    "X_train_final = X_train_final.values\n",
    "X_valid = X_valid.values\n",
    "y_train_final = y_train_final.values\n",
    "y_valid = y_valid.values\n",
    "\n",
    "model = shallow_NN(len(columns), args['num_classes'], layer_nodes=args['final_params']['layer_nodes'])\n",
    "    \n",
    "early_stop = CustomStopper(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='min', \n",
    "                           start_epoch=args['early_stop_start'],\n",
    "                           restore_best_weights=True)\n",
    "\n",
    "y_train_final_categorical = keras_categorical(y_train_final, args['num_classes'])\n",
    "y_valid_categorical = keras_categorical(y_valid, args['num_classes'])\n",
    "\n",
    "log_msg(\">>> Training \")\n",
    "model.fit(X_train_final, y_train_final_categorical, \n",
    "          batch_size=args['batch_size'], \n",
    "          epochs=args['max_epochs'], \n",
    "          validation_data=(X_valid, y_valid_categorical),\n",
    "          verbose=args['verbose'],\n",
    "          callbacks=[early_stop])\n",
    "\n",
    "log_msg(\">>> Finished!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_valid)\n",
    "y_pred = y_pred[:,1]\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_valid, y_pred)\n",
    "\n",
    "reports = precision_reall_f1_report(precision, recall, thresholds, \n",
    "                                    font_scale=2,\n",
    "                                    linewidth=3,\n",
    "                                    plot=False)\n",
    "\n",
    "threshold = reports[reports['f1']==reports['f1'].max()]['threshold'].values[0]\n",
    "\n",
    "print('Threshold to get the best F1 on validation set: ', threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred[:,1]\n",
    "\n",
    "print(f\">>> AUC on Test set: {roc_auc_score(y_test, y_pred)}\\n\")\n",
    "\n",
    "y_pred_label = [1 if i >= threshold else 0 for i in y_pred]\n",
    "\n",
    "print(f\">>> F1 on Test set (threshold {threshold}) : {f1_score(y_test, y_pred_label)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, Recall and F1 vs threshold on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = precision_reall_f1_report(precision, recall, thresholds, \n",
    "                                    font_scale=2,\n",
    "                                    linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best F1: ', reports['f1'].max())\n",
    "print('Threshold:', reports[reports['f1']==reports['f1'].max()]['threshold'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
